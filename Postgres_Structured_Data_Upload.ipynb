{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1734a355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import decimal\n",
    "import psycopg2\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a49f9a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db3b691a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the PostgreSQL database\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    database=\"postgres\",\n",
    "    user=\"postgres\",\n",
    "    password=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb442220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a cursor to perform database operations\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c19ee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c9350a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_user_info(tweet):\n",
    "    try:\n",
    "        \n",
    "#         cur.execute(\"\"\"\n",
    "#         INSERT INTO twitter_users_partitioned \n",
    "#         (user_id, name, screen_name, date, twitter_join_date, location, description, \n",
    "#         verified, followers_count, friends_count, listed_count, favourites_count, language)\n",
    "#         VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "#     \"\"\", (tweet['user']['id'], tweet['user']['name'], tweet['screen_name'], tweet['created_at'], \n",
    "#           tweet['user']['created_at'], tweet['user']['location'], tweet['user']['description'], \n",
    "#           tweet['user']['verified'], tweet['user']['followers_count'], tweet['user']['friends_count'], \n",
    "#           tweet['user']['listed_count'], tweet['user']['favourites_count'], tweet['user']['lang']))\n",
    "        \n",
    "        users.append({'user_id': tweet['user']['id'], \n",
    "                      'name': tweet['user']['name'], \n",
    "                      'screen_name': tweet['user']['screen_name'], \n",
    "                      'date': tweet['created_at'],\n",
    "                      'twitter_join_date': tweet['user']['created_at'], \n",
    "                      'location': tweet['user']['location'], \n",
    "                      'description': tweet['user']['description'], \n",
    "                      'verified': tweet['user']['verified'], \n",
    "                      'followers_count': tweet['user']['followers_count'], \n",
    "                      'friends_count': tweet['user']['friends_count'],\n",
    "                      'listed_count': tweet['user']['listed_count'], \n",
    "                      'favourites_count': tweet['user']['favourites_count'],\n",
    "                      'language': tweet['user']['lang']})\n",
    "#         conn.commit()\n",
    "#         cur.close()\n",
    "#         conn.close()\n",
    "\n",
    "    except Exception as e:\n",
    "#         conn.rollback()\n",
    "#         cur.close()\n",
    "#         conn.close()\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d1019c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    # Load the JSON data from file\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                tweet = json.loads(line)\n",
    "                # insert user entry into database\n",
    "                insert_user_info(tweet)\n",
    "                # if there is a retweet, get original user from retweet\n",
    "                if (tweet['text'].startswith('RT')):\n",
    "                    original_tweet = tweet[\"retweeted_status\"]\n",
    "                    insert_user_info(original_tweet)\n",
    "            except:\n",
    "                # if there is an error loading the json of the tweet, skip\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "384b406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data(\"../corona-out-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9e50341",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data(\"../corona-out-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83a91181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas DataFrame from the parsed data\n",
    "df_users = pd.DataFrame(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4120b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>date</th>\n",
       "      <th>twitter_join_date</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "      <th>verified</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1242817830946508801</td>\n",
       "      <td>juwelz v</td>\n",
       "      <td>juwelz_v</td>\n",
       "      <td>Sun Apr 12 18:27:25 +0000 2020</td>\n",
       "      <td>Wed Mar 25 14:17:28 +0000 2020</td>\n",
       "      <td>Lower East Side, Manhattan</td>\n",
       "      <td>Event Lyfe LLC .. Brand Ambassador: #visionary...</td>\n",
       "      <td>False</td>\n",
       "      <td>43</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>722</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16144221</td>\n",
       "      <td>NUFF</td>\n",
       "      <td>nuffsaidny</td>\n",
       "      <td>Sun Apr 12 16:48:01 +0000 2020</td>\n",
       "      <td>Fri Sep 05 14:28:41 +0000 2008</td>\n",
       "      <td>None</td>\n",
       "      <td>instagram: @nuffsaidny ðŸ‡¹ðŸ‡¹</td>\n",
       "      <td>False</td>\n",
       "      <td>17112</td>\n",
       "      <td>1515</td>\n",
       "      <td>874</td>\n",
       "      <td>15790</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1225145123920588805</td>\n",
       "      <td>efe09</td>\n",
       "      <td>efe0927183508</td>\n",
       "      <td>Sun Apr 12 18:27:25 +0000 2020</td>\n",
       "      <td>Wed Feb 05 19:52:38 +0000 2020</td>\n",
       "      <td>None</td>\n",
       "      <td>Allah'Ä±n en deÄŸerli eseri insandÄ±r.\\nCanÄ± yana...</td>\n",
       "      <td>False</td>\n",
       "      <td>653</td>\n",
       "      <td>983</td>\n",
       "      <td>0</td>\n",
       "      <td>1255</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1087735689091928064</td>\n",
       "      <td>Karanfil Lale</td>\n",
       "      <td>lale_karanfil</td>\n",
       "      <td>Sun Apr 12 18:02:41 +0000 2020</td>\n",
       "      <td>Tue Jan 22 15:36:12 +0000 2019</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>897</td>\n",
       "      <td>1120</td>\n",
       "      <td>1</td>\n",
       "      <td>2776</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101007632</td>\n",
       "      <td>Ravin Gupta</td>\n",
       "      <td>IamRaavin</td>\n",
       "      <td>Sun Apr 12 18:27:26 +0000 2020</td>\n",
       "      <td>Fri Jan 01 16:24:24 +0000 2010</td>\n",
       "      <td>india</td>\n",
       "      <td>Tweet is personal opinion and Retweet is not e...</td>\n",
       "      <td>False</td>\n",
       "      <td>499</td>\n",
       "      <td>537</td>\n",
       "      <td>2</td>\n",
       "      <td>4342</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               user_id           name    screen_name  \\\n",
       "0  1242817830946508801       juwelz v       juwelz_v   \n",
       "1             16144221           NUFF     nuffsaidny   \n",
       "2  1225145123920588805          efe09  efe0927183508   \n",
       "3  1087735689091928064  Karanfil Lale  lale_karanfil   \n",
       "4            101007632    Ravin Gupta      IamRaavin   \n",
       "\n",
       "                             date               twitter_join_date  \\\n",
       "0  Sun Apr 12 18:27:25 +0000 2020  Wed Mar 25 14:17:28 +0000 2020   \n",
       "1  Sun Apr 12 16:48:01 +0000 2020  Fri Sep 05 14:28:41 +0000 2008   \n",
       "2  Sun Apr 12 18:27:25 +0000 2020  Wed Feb 05 19:52:38 +0000 2020   \n",
       "3  Sun Apr 12 18:02:41 +0000 2020  Tue Jan 22 15:36:12 +0000 2019   \n",
       "4  Sun Apr 12 18:27:26 +0000 2020  Fri Jan 01 16:24:24 +0000 2010   \n",
       "\n",
       "                     location  \\\n",
       "0  Lower East Side, Manhattan   \n",
       "1                        None   \n",
       "2                        None   \n",
       "3                        None   \n",
       "4                       india   \n",
       "\n",
       "                                         description  verified  \\\n",
       "0  Event Lyfe LLC .. Brand Ambassador: #visionary...     False   \n",
       "1                          instagram: @nuffsaidny ðŸ‡¹ðŸ‡¹     False   \n",
       "2  Allah'Ä±n en deÄŸerli eseri insandÄ±r.\\nCanÄ± yana...     False   \n",
       "3                                               None     False   \n",
       "4  Tweet is personal opinion and Retweet is not e...     False   \n",
       "\n",
       "   followers_count  friends_count  listed_count  favourites_count language  \n",
       "0               43            118             0               722     None  \n",
       "1            17112           1515           874             15790     None  \n",
       "2              653            983             0              1255     None  \n",
       "3              897           1120             1              2776     None  \n",
       "4              499            537             2              4342     None  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "706149f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users['date'] = pd.to_datetime(df_users['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28d7e6c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "twitter_join_date\n",
       "2006       19\n",
       "2007     2012\n",
       "2008     2785\n",
       "2009    19945\n",
       "2010    15987\n",
       "2011    14673\n",
       "2012    15015\n",
       "2013    12344\n",
       "2014    11767\n",
       "2015    10409\n",
       "2016    12793\n",
       "2017    14007\n",
       "2018    15580\n",
       "2019    24308\n",
       "2020    21050\n",
       "Name: twitter_join_date, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users['twitter_join_date'] = pd.to_datetime(df_users['twitter_join_date'])\n",
    "df_users.groupby(df_users['twitter_join_date'].dt.year)['twitter_join_date'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a80d942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-06-03 15:32:48+00:00\n",
      "2020-04-25 14:48:38+00:00\n"
     ]
    }
   ],
   "source": [
    "min_date = df_users['date'].min()\n",
    "max_date = df_users['date'].max()\n",
    "print(min_date)\n",
    "print(max_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5641c069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2020-01-01 00:00:00+00:00         0\n",
       "2020-01-02 00:00:00+00:00         0\n",
       "2020-01-03 00:00:00+00:00         0\n",
       "2020-01-04 00:00:00+00:00         0\n",
       "2020-01-05 00:00:00+00:00         0\n",
       "2020-01-06 00:00:00+00:00         0\n",
       "2020-01-07 00:00:00+00:00         0\n",
       "2020-01-08 00:00:00+00:00         0\n",
       "2020-01-09 00:00:00+00:00         0\n",
       "2020-01-10 00:00:00+00:00         0\n",
       "2020-01-11 00:00:00+00:00         0\n",
       "2020-01-12 00:00:00+00:00         0\n",
       "2020-01-13 00:00:00+00:00         0\n",
       "2020-01-14 00:00:00+00:00         1\n",
       "2020-01-15 00:00:00+00:00         0\n",
       "2020-01-16 00:00:00+00:00         0\n",
       "2020-01-17 00:00:00+00:00         0\n",
       "2020-01-18 00:00:00+00:00         0\n",
       "2020-01-19 00:00:00+00:00         0\n",
       "2020-01-20 00:00:00+00:00         0\n",
       "2020-01-21 00:00:00+00:00         0\n",
       "2020-01-22 00:00:00+00:00         0\n",
       "2020-01-23 00:00:00+00:00         0\n",
       "2020-01-24 00:00:00+00:00         0\n",
       "2020-01-25 00:00:00+00:00         1\n",
       "2020-01-26 00:00:00+00:00         2\n",
       "2020-01-27 00:00:00+00:00         0\n",
       "2020-01-28 00:00:00+00:00         0\n",
       "2020-01-29 00:00:00+00:00         1\n",
       "2020-01-30 00:00:00+00:00         1\n",
       "2020-01-31 00:00:00+00:00         0\n",
       "2020-02-01 00:00:00+00:00         0\n",
       "2020-02-02 00:00:00+00:00         3\n",
       "2020-02-03 00:00:00+00:00         1\n",
       "2020-02-04 00:00:00+00:00         2\n",
       "2020-02-05 00:00:00+00:00         0\n",
       "2020-02-06 00:00:00+00:00         1\n",
       "2020-02-07 00:00:00+00:00         0\n",
       "2020-02-08 00:00:00+00:00         0\n",
       "2020-02-09 00:00:00+00:00         0\n",
       "2020-02-10 00:00:00+00:00         2\n",
       "2020-02-11 00:00:00+00:00         1\n",
       "2020-02-12 00:00:00+00:00         5\n",
       "2020-02-13 00:00:00+00:00         0\n",
       "2020-02-14 00:00:00+00:00         1\n",
       "2020-02-15 00:00:00+00:00         0\n",
       "2020-02-16 00:00:00+00:00         0\n",
       "2020-02-17 00:00:00+00:00         1\n",
       "2020-02-18 00:00:00+00:00         1\n",
       "2020-02-19 00:00:00+00:00         0\n",
       "2020-02-20 00:00:00+00:00         0\n",
       "2020-02-21 00:00:00+00:00         1\n",
       "2020-02-22 00:00:00+00:00         1\n",
       "2020-02-23 00:00:00+00:00         3\n",
       "2020-02-24 00:00:00+00:00         4\n",
       "2020-02-25 00:00:00+00:00         1\n",
       "2020-02-26 00:00:00+00:00         4\n",
       "2020-02-27 00:00:00+00:00         1\n",
       "2020-02-28 00:00:00+00:00         5\n",
       "2020-02-29 00:00:00+00:00         0\n",
       "2020-03-01 00:00:00+00:00         0\n",
       "2020-03-02 00:00:00+00:00         4\n",
       "2020-03-03 00:00:00+00:00         5\n",
       "2020-03-04 00:00:00+00:00         4\n",
       "2020-03-05 00:00:00+00:00         5\n",
       "2020-03-06 00:00:00+00:00         3\n",
       "2020-03-07 00:00:00+00:00         4\n",
       "2020-03-08 00:00:00+00:00         1\n",
       "2020-03-09 00:00:00+00:00         5\n",
       "2020-03-10 00:00:00+00:00         6\n",
       "2020-03-11 00:00:00+00:00         7\n",
       "2020-03-12 00:00:00+00:00        26\n",
       "2020-03-13 00:00:00+00:00        26\n",
       "2020-03-14 00:00:00+00:00        13\n",
       "2020-03-15 00:00:00+00:00        26\n",
       "2020-03-16 00:00:00+00:00        29\n",
       "2020-03-17 00:00:00+00:00        35\n",
       "2020-03-18 00:00:00+00:00        22\n",
       "2020-03-19 00:00:00+00:00        22\n",
       "2020-03-20 00:00:00+00:00        38\n",
       "2020-03-21 00:00:00+00:00        27\n",
       "2020-03-22 00:00:00+00:00        38\n",
       "2020-03-23 00:00:00+00:00        44\n",
       "2020-03-24 00:00:00+00:00        32\n",
       "2020-03-25 00:00:00+00:00        53\n",
       "2020-03-26 00:00:00+00:00        38\n",
       "2020-03-27 00:00:00+00:00        48\n",
       "2020-03-28 00:00:00+00:00        36\n",
       "2020-03-29 00:00:00+00:00        20\n",
       "2020-03-30 00:00:00+00:00        39\n",
       "2020-03-31 00:00:00+00:00        28\n",
       "2020-04-01 00:00:00+00:00        42\n",
       "2020-04-02 00:00:00+00:00        48\n",
       "2020-04-03 00:00:00+00:00        34\n",
       "2020-04-04 00:00:00+00:00        46\n",
       "2020-04-05 00:00:00+00:00        51\n",
       "2020-04-06 00:00:00+00:00        83\n",
       "2020-04-07 00:00:00+00:00        59\n",
       "2020-04-08 00:00:00+00:00        95\n",
       "2020-04-09 00:00:00+00:00       133\n",
       "2020-04-10 00:00:00+00:00       215\n",
       "2020-04-11 00:00:00+00:00       913\n",
       "2020-04-12 00:00:00+00:00     28200\n",
       "2020-04-13 00:00:00+00:00        48\n",
       "2020-04-14 00:00:00+00:00        60\n",
       "2020-04-15 00:00:00+00:00        71\n",
       "2020-04-16 00:00:00+00:00       120\n",
       "2020-04-17 00:00:00+00:00        95\n",
       "2020-04-18 00:00:00+00:00       131\n",
       "2020-04-19 00:00:00+00:00       149\n",
       "2020-04-20 00:00:00+00:00       198\n",
       "2020-04-21 00:00:00+00:00       335\n",
       "2020-04-22 00:00:00+00:00       933\n",
       "2020-04-23 00:00:00+00:00      1908\n",
       "2020-04-24 00:00:00+00:00      7054\n",
       "2020-04-25 00:00:00+00:00    150939\n",
       "Freq: D, Name: date, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates_2020 = df_users.groupby(pd.Grouper(key='date', freq='D'))['date'].count().loc['2020-01-01':'2020-04-25']\n",
    "dates_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c31f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.to_csv('data/users.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a9314c",
   "metadata": {},
   "source": [
    "Based on the distribution of the rows in the date column, we can create partitions on the data based on its year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e65711",
   "metadata": {},
   "source": [
    "Two indexes were recommended to optimize searching for users by their name, number of followers, and verification status. \n",
    "A single column index is used for the \"name\" column, since it is the primary search criterion. A compound index on the \"followers_count\" and \"verified\" columns is created to sort and filter records based on the priority of number of followers and verification status. The \"followers_count\" is specified first in the index definition with a descending order, since sorting in descending order allows for efficient filtering based on the maximum number of followers. These indexing strategies will help speed up query times while minimizing the impact on write performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c7ae19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an index on the \"name\" column\n",
    "cur.execute(\"CREATE INDEX name_idx_p ON twitter_users_partitioned (name);\")\n",
    "conn.commit()\n",
    "\n",
    "# Create a compound index on the \"followers_count\" and \"verified\" columns\n",
    "cur.execute(\"CREATE INDEX followers_verified_idx_p ON twitter_users_partitioned (followers_count DESC, verified);\")\n",
    "conn.commit()\n",
    "\n",
    "# Close the database connection\n",
    "#conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e2ea7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57122b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     for index, row in users_df.iterrows():\n",
    "#         cur.execute(\"\"\"\n",
    "#             INSERT INTO twitter_users (user_id, name, screen_name, date, twitter_join_date, location, description, verified, followers_count, friends_count, listed_count, favourites_count, preferred_language)\n",
    "#             VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "#             ON CONFLICT (user_id) DO UPDATE\n",
    "#             SET name = excluded.name,\n",
    "#                 screen_name = excluded.screen_name,\n",
    "#                 twitter_join_date = excluded.twitter_join_date,\n",
    "#                 location = excluded.location,\n",
    "#                 description = excluded.description,\n",
    "#                 verified = excluded.verified,\n",
    "#                 followers_count = excluded.followers_count,\n",
    "#                 friends_count = excluded.friends_count,\n",
    "#                 listed_count = excluded.listed_count,\n",
    "#                 favourites_count = excluded.favourites_count,\n",
    "#                 preferred_language = excluded.preferred_language;\n",
    "#         \"\"\", (row['user_id'], row['name'], row['screen_name'], row['date'], row['twitter_join_date'], row['location'], row['description'], row['verified'], row['followers_count'], row['friends_count'], row['listed_count'], row['favourites_count'], row['preferred_language']))\n",
    "\n",
    "# except Exception as e:\n",
    "#     conn.rollback()\n",
    "#     cur.close()\n",
    "#     conn.close()\n",
    "#     print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087de12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query('''SELECT EXTRACT(YEAR FROM twitter_join_date) AS year, count(*)\n",
    "\tFROM public.twitter_users group by EXTRACT(YEAR FROM twitter_join_date)\n",
    "\torder by EXTRACT(YEAR FROM twitter_join_date);''', con = conn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
