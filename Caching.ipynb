{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89f7891d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pymongo\n",
    "import psycopg2\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d374d1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import OrderedDict\n",
    "\n",
    "class SearchCache:\n",
    "    def __init__(self, max_size=1000, ttl=3600):\n",
    "        \"\"\"\n",
    "        Initializes the cache with a maximum size and time-to-live (ttl) values.\n",
    "\n",
    "        Args:\n",
    "        - max_size (int): Maximum number of items that the cache can hold.\n",
    "        - ttl (int): Time-to-live of each cache entry in seconds.\n",
    "        \"\"\"\n",
    "        self.max_size = max_size\n",
    "        self.ttl = ttl\n",
    "        # initialize an ordered dictionary that will be used as the cache\n",
    "        self.cache = OrderedDict()\n",
    "\n",
    "    def __contains__(self, key):\n",
    "        \"\"\"\n",
    "        Returns a boolean value indicating if a key is present in the cache.\n",
    "\n",
    "        Args:\n",
    "        - key (str): Key to look up in the cache.\n",
    "\n",
    "        Returns:\n",
    "        - bool: True if the key is present in the cache, False otherwise.\n",
    "        \"\"\"\n",
    "        return key in self.cache\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Retrieves the value and timestamp from the cache for a given key.\n",
    "\n",
    "        Args:\n",
    "        - key (str): Key to look up in the cache.\n",
    "\n",
    "        Returns:\n",
    "        - Any: Value associated with the given key.\n",
    "\n",
    "        Raises:\n",
    "        - KeyError: If the cache entry has expired.\n",
    "        \"\"\"\n",
    "        # retrieve the value and timestamp from the cache for a given key\n",
    "        value, timestamp = self.cache[key]\n",
    "        # check if the cache entry has expired by comparing its timestamp with the current time\n",
    "        if time.time() - timestamp > self.ttl:\n",
    "            # remove the expired cache entry\n",
    "            self.cache.pop(key)\n",
    "            # raise a KeyError with a message indicating the cache entry has expired\n",
    "            raise KeyError('Cache entry has expired')\n",
    "        # move the accessed cache entry to the end of the ordered dictionary\n",
    "        self.cache.move_to_end(key)\n",
    "        # return the value associated with the given key\n",
    "        return value\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        \"\"\"\n",
    "        Adds or updates a cache entry for the given key with its corresponding value and timestamp.\n",
    "\n",
    "        Args:\n",
    "        - key (str): Key to add or update in the cache.\n",
    "        - value (Any): Value to associate with the given key in the cache.\n",
    "        \"\"\"\n",
    "        # check if the given key is already present in the cache\n",
    "        if key in self.cache:\n",
    "            # move the existing cache entry to the end of the ordered dictionary\n",
    "            self.cache.move_to_end(key)\n",
    "        # adds a new cache entry for the given key with its corresponding value and timestamp\n",
    "        self.cache[key] = (value, time.time())\n",
    "        # check if the cache has exceeded its maximum size\n",
    "        if len(self.cache) > self.max_size:\n",
    "            # remove the least recently used cache entry (i.e., the first item in the ordered dictionary)\n",
    "            self.cache.popitem(last=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9bb89bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import psycopg2\n",
    "\n",
    "class SearchEngine:\n",
    "    def __init__(self, db_type, cache_size=100, cache_ttl=3600):\n",
    "        \"\"\"\n",
    "        Initializes a SearchEngine object with a specified database type and cache settings.\n",
    "\n",
    "        Args:\n",
    "        - db_type (str): Either \"mongodb\" or \"postgresql\"\n",
    "        - cache_size (int): Maximum number of items to store in cache\n",
    "        - cache_ttl (int): Time-to-live (in seconds) for cached items\n",
    "        \"\"\"\n",
    "        # initialize the search engine with a database type and cache size/ttl values\n",
    "        self.db_type = db_type\n",
    "        # initialize a cache object for the search engine using the SearchCache class\n",
    "        self.cache = SearchCache(cache_size, cache_ttl)\n",
    "        # establish a database connection based on the given database type\n",
    "        if self.db_type == 'mongodb':\n",
    "            self.db_client = pymongo.MongoClient('mongodb+srv://<user>:<password>@cluster0.wkyhu.mongodb.net/?retryWrites=true&w=majority')\n",
    "            self.tweets_collection = self.db_client['twitter_db']['tweets_data']\n",
    "        elif self.db_type == 'postgresql':\n",
    "            self.db_conn = psycopg2.connect(database=\"twitter_db\", user=\"postgres\", password=\"\", host=\"localhost\")\n",
    "            self.users_cursor = self.db_conn.cursor()\n",
    "        else:\n",
    "            # raise a ValueError if an invalid database type is given\n",
    "            raise ValueError('Invalid database type')\n",
    "\n",
    "    def get_top_hashtags(self, n=10):\n",
    "        \"\"\"\n",
    "        Retrieves the top N most frequently used hashtags from the database or cache.\n",
    "\n",
    "        Args:\n",
    "        - n (int): Number of top hashtags to retrieve\n",
    "\n",
    "        Returns:\n",
    "        - top_hashtags (list): A list of dictionaries representing the top N hashtags, sorted by frequency of use\n",
    "        \"\"\"\n",
    "        # check if the 'top_hashtags' key is present in the cache\n",
    "        if 'top_hashtags' in self.cache:\n",
    "            # retrieve the cached top hashtags and returns the first n items\n",
    "            return self.cache['top_hashtags'][:n]\n",
    "        else:\n",
    "            # define a pipeline for aggregating top hashtags from the tweets collection\n",
    "            pipeline = [\n",
    "                {\"$unwind\": \"$entities.hashtags\"},\n",
    "                {\"$group\": {\"_id\": \"$entities.hashtags.text\", \"count\": {\"$sum\": 1}}},\n",
    "                {\"$sort\": {\"count\": -1}},\n",
    "                {\"$limit\": 100}\n",
    "            ]\n",
    "            top_hashtags = list(self.tweets_collection.aggregate(pipeline))\n",
    "            self.cache['top_hashtags'] = top_hashtags\n",
    "            return top_hashtags[:n]\n",
    "\n",
    "    def get_popular_users(self, n=10):\n",
    "        \"\"\"\n",
    "        Retrieves the top N most popular users (by number of tweets) from the database or cache.\n",
    "\n",
    "        Args:\n",
    "        - n (int): Number of top users to retrieve\n",
    "\n",
    "        Returns:\n",
    "        - popular_users (list): A list of dictionaries representing the top N users, sorted by number of tweets\n",
    "        \"\"\"\n",
    "        # if the popular users are already cached, return the cached list of popular users\n",
    "        if 'popular_users' in self.cache:\n",
    "            return self.cache['popular_users'][:n]\n",
    "        else:\n",
    "            # query Postgres for user data\n",
    "            self.users_cursor.execute(\"SELECT id, name, screen_name, followers_count FROM twitter_users\")\n",
    "            users_data = self.users_cursor.fetchall()\n",
    "            # get tweets count for each user from MongoDB\n",
    "            users_tweets_count = {}\n",
    "            for user_data in users_data:\n",
    "                user_id = user_data[0]\n",
    "                tweets_count = self.tweets_collection.count_documents({'user_id': user_id})\n",
    "                users_tweets_count[user_id] = tweets_count\n",
    "            # sort users by number of tweets and return top N\n",
    "            sorted_users = sorted(users_data, key=lambda user_data: users_tweets_count[user_data[0]], reverse=True)\n",
    "            popular_users = [{\"id\": row[0], \"name\": row[1], \"screen_name\": row[2], \"followers_count\": row[3], \"count\": users_tweets_count[row[0]]} for row in sorted_users]\n",
    "            self.cache['popular_users'] = popular_users\n",
    "            return popular_users[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a788806c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
